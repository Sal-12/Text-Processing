{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing  and text cleaning for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitter_data.csv', encoding = 'latin1') #https://twitter-sentiment-csv.herokuapp.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     58\n",
       "positive    26\n",
       "negative    13\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @byLilyV: #FEATURED #COURSES\\n\\n#Machine #L...</td>\n",
       "      <td>Women_who_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @byLilyV: #FEATURED #COURSES\\n\\n#Machine #L...</td>\n",
       "      <td>xaelbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @byLilyV: #FEATURED #COURSES\\n\\n#Machine #L...</td>\n",
       "      <td>epuujee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>#FEATURED #COURSES\\n\\n#Machine #Learning A-Zâ...</td>\n",
       "      <td>byLilyV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>RT @SuriyaSubraman: Top 5 Data Science Certifi...</td>\n",
       "      <td>epuujee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>positive</td>\n",
       "      <td>RT @DataScientistsF: Coursera âIBM Data Scie...</td>\n",
       "      <td>chidambara09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @LaForge_AI: How data science is driving in...</td>\n",
       "      <td>hubofml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @TheRiverSevern: Anyone want to join @WUFou...</td>\n",
       "      <td>epuujee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Jer1dah: Don't sleep on Udemy. There are f...</td>\n",
       "      <td>DiatonicM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @LaForge_AI: How data science is driving in...</td>\n",
       "      <td>andrewmorrisuk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0    neutral  RT @byLilyV: #FEATURED #COURSES\\n\\n#Machine #L...   \n",
       "1    neutral  RT @byLilyV: #FEATURED #COURSES\\n\\n#Machine #L...   \n",
       "2    neutral  RT @byLilyV: #FEATURED #COURSES\\n\\n#Machine #L...   \n",
       "3    neutral  #FEATURED #COURSES\\n\\n#Machine #Learning A-Zâ...   \n",
       "4   positive  RT @SuriyaSubraman: Top 5 Data Science Certifi...   \n",
       "..       ...                                                ...   \n",
       "92  positive  RT @DataScientistsF: Coursera âIBM Data Scie...   \n",
       "93   neutral  RT @LaForge_AI: How data science is driving in...   \n",
       "94   neutral  RT @TheRiverSevern: Anyone want to join @WUFou...   \n",
       "95   neutral  RT @Jer1dah: Don't sleep on Udemy. There are f...   \n",
       "96   neutral  RT @LaForge_AI: How data science is driving in...   \n",
       "\n",
       "              user  \n",
       "0   Women_who_code  \n",
       "1          xaelbot  \n",
       "2          epuujee  \n",
       "3          byLilyV  \n",
       "4          epuujee  \n",
       "..             ...  \n",
       "92    chidambara09  \n",
       "93         hubofml  \n",
       "94         epuujee  \n",
       "95       DiatonicM  \n",
       "96  andrewmorrisuk  \n",
       "\n",
       "[97 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     18\n",
       "1     18\n",
       "2     18\n",
       "3     16\n",
       "4     24\n",
       "      ..\n",
       "92    15\n",
       "93    14\n",
       "94    22\n",
       "95    24\n",
       "96    14\n",
       "Name: word_count, Length: 97, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>positive</td>\n",
       "      <td>RT @vrilock: Do policy-makers actually take th...</td>\n",
       "      <td>epuujee</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>positive</td>\n",
       "      <td>timely takeaway from today's microbio seminar:...</td>\n",
       "      <td>Enkkkkkkk7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Jer1dah: Don't sleep on Udemy. There are f...</td>\n",
       "      <td>GiftOfShange</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @SuriyaSubraman: National Big Data Health S...</td>\n",
       "      <td>epuujee</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Jer1dah: Don't sleep on Udemy. There are f...</td>\n",
       "      <td>dukesy19x</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text          user  \\\n",
       "62  positive  RT @vrilock: Do policy-makers actually take th...       epuujee   \n",
       "54  positive  timely takeaway from today's microbio seminar:...    Enkkkkkkk7   \n",
       "72   neutral  RT @Jer1dah: Don't sleep on Udemy. There are f...  GiftOfShange   \n",
       "5    neutral  RT @SuriyaSubraman: National Big Data Health S...       epuujee   \n",
       "57   neutral  RT @Jer1dah: Don't sleep on Udemy. There are f...     dukesy19x   \n",
       "\n",
       "    word_count  \n",
       "62          21  \n",
       "54          17  \n",
       "72          24  \n",
       "5           21  \n",
       "57          24  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_count'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_count'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "      ...  \n",
       "92    False\n",
       "93    False\n",
       "94    False\n",
       "95    False\n",
       "96    False\n",
       "Name: word_count, Length: 97, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_count']==3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@shujaat_bukhari @ameerhamza11022 https://t.co...</td>\n",
       "      <td>shobz</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text   user  \\\n",
       "75   neutral  @shujaat_bukhari @ameerhamza11022 https://t.co...  shobz   \n",
       "\n",
       "    word_count  \n",
       "75           3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['word_count']==3]  # Only 3 twits from this user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     152\n",
       "1     152\n",
       "2     152\n",
       "3     152\n",
       "4     142\n",
       "     ... \n",
       "92    146\n",
       "93    145\n",
       "94    142\n",
       "95    143\n",
       "96    145\n",
       "Name: char_count, Length: 97, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['char_count'] = df['text'].apply(lambda x: len(x))\n",
    "df['char_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem with the char count is that it also counts the spaces for that we use the following def function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_count(x):\n",
    "    s = x.split() # splits the whole text\n",
    "    x = ''.join(s) # joins the whole text\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['char_count'] = df['text'].apply(lambda x: char_count(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     135\n",
       "1     135\n",
       "2     135\n",
       "3     137\n",
       "4     119\n",
       "     ... \n",
       "92    132\n",
       "93    132\n",
       "94    121\n",
       "95    120\n",
       "96    132\n",
       "Name: char_count, Length: 97, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['char_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Eli_Krumova: How to Evaluate a #DataScienc...</td>\n",
       "      <td>BotFemale</td>\n",
       "      <td>12</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Jer1dah: Don't sleep on Udemy. There are f...</td>\n",
       "      <td>vuyi_chaza</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Eli_Krumova: How to Evaluate a #DataScienc...</td>\n",
       "      <td>friday_Js_bot</td>\n",
       "      <td>12</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "13   neutral  RT @Eli_Krumova: How to Evaluate a #DataScienc...   \n",
       "86   neutral  RT @Jer1dah: Don't sleep on Udemy. There are f...   \n",
       "16   neutral  RT @Eli_Krumova: How to Evaluate a #DataScienc...   \n",
       "\n",
       "             user  word_count  char_count  \n",
       "13      BotFemale          12         134  \n",
       "86     vuyi_chaza          24         120  \n",
       "16  friday_Js_bot          12         134  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7.5\n",
       "1    7.5\n",
       "2    7.5\n",
       "Name: Avg_word_len, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Avg_word_len'] = df['char_count']/df['word_count']\n",
    "df['Avg_word_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7.5\n",
       "1    7.5\n",
       "2    7.5\n",
       "Name: Avg_word_len, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Avg_word_len'] = df['char_count']/df['word_count']\n",
    "df['Avg_word_len'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81     5.000000\n",
       "37    15.000000\n",
       "88    11.583333\n",
       "83     8.800000\n",
       "Name: Avg_word_len, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['Avg_word_len'] = df['char_count']/df['word_count']\n",
    "df['Avg_word_len'].sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hers', \"n't\", 'to', 'before', \"'s\", 'while', 'next', 'well', 'put', 'nevertheless', 'an', 'everything', 'now', 'our', 'whereby', 'sixty', 'perhaps', 'once', 'beyond', 'there', 'doing', 'within', 'every', 'herself', 'various', 'he', 'could', \"'ll\", 'due', 'twelve', 'was', 'beside', 'regarding', 'too', 'her', 'anyhow', 'fifteen', 'move', 'and', 'though', 'n’t', 'if', 'below', '’re', '‘ll', 'used', 'in', 'again', 'from', 'through', 'except', 're', 'quite', '‘d', 'hereafter', 'over', 'above', 'each', 'but', 'else', 'take', 'they', 'anywhere', 'anyway', 'throughout', 'whereafter', 'together', '‘re', 'someone', 'seemed', 'should', 'are', 'keep', 'thereafter', 'itself', 'yet', 'off', 'us', 'here', 'this', 'thence', 'eleven', 'otherwise', '’d', 'whence', 'has', 'enough', 'himself', 'toward', 'other', 'empty', 'neither', 'thereby', 'name', 'does', 'or', 'much', 'on', 'herein', 'thru', 'besides', 'get', 'made', 'hereby', 'must', 'using', 'at', 'ourselves', 'can', 'whatever', 'just', 'unless', 'further', 'why', 'be', 'whose', 'only', 'so', 'nobody', '‘m', 'everywhere', 'their', 'a', 'out', 'hundred', 'four', '‘s', 'however', 'formerly', 'therefore', 'seem', 'n‘t', 'seems', 'with', 'none', 'she', 'after', 'his', 'not', 'nine', 'five', 'often', 'would', 'me', 'the', 'few', 'behind', 'call', 'three', 'latter', 'nowhere', 'its', 'cannot', 'always', 'amount', 'nor', 'one', 'therein', 'no', 'both', 'am', 'been', 'between', 'it', 'per', 'by', 'will', 'side', \"'ve\", 'third', '‘ve', 'everyone', 'beforehand', 'among', 'anyone', 'front', 'namely', 'former', 'whole', 'had', 'ca', 'moreover', 'them', 'any', 'even', 'make', 'almost', 'six', 'mostly', 'may', 'who', 'back', 'which', 'how', 'hereupon', '’m', 'as', 'less', 'against', 'until', 'ever', 'ours', 'something', 'of', 'onto', 'whereas', 'already', 'becomes', 'more', 'where', 'another', 'two', 'least', 'serious', 'many', 'top', 'done', 'your', 'when', 'sometime', 'somehow', 'whereupon', 'those', 'nothing', 'give', 'because', 'whither', 'full', 'is', 'via', 'either', 'last', 'upon', \"'re\", 'afterwards', 'become', 'show', 'go', 'latterly', 'i', 'eight', 'bottom', 'say', 'thus', 'seeming', 'also', 'see', 'anything', 'yourselves', 'still', 'becoming', 'alone', 'although', 'whoever', 'mine', 'under', 'yourself', 'wherein', 'you', 'own', \"'m\", 'fifty', 'yours', 'please', 'into', 'do', 'others', 'twenty', 'we', '’ll', 'have', 'elsewhere', 'very', 'towards', 'about', 'myself', 'ten', 'amongst', 'around', 'such', 'themselves', 'that', 'forty', 'never', 'whenever', 'then', 'did', 'several', 'whether', 'indeed', '’s', 'hence', 'became', 'since', 'along', 'these', \"'d\", 'were', 'some', '’ve', 'first', 'down', 'my', 'during', 'thereupon', 'for', 'same', 'meanwhile', 'up', 'what', 'really', 'most', 'sometimes', 'without', 'him', 'across', 'being', 'than', 'noone', 'rather', 'all', 'somewhere', 'part', 'wherever', 'might', 'whom'}\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[t for t in x.split() if t in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len_stop_words'] = df['text'].apply(lambda x: len([t for t in x.split() if t in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     9\n",
       "     ..\n",
       "92    0\n",
       "93    2\n",
       "94    8\n",
       "95    8\n",
       "96    2\n",
       "Name: len_stop_words, Length: 97, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['len_stop_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Avg_word_len</th>\n",
       "      <th>len_stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Eli_Krumova: How to Evaluate a #DataScienc...</td>\n",
       "      <td>seerberos</td>\n",
       "      <td>12</td>\n",
       "      <td>134</td>\n",
       "      <td>11.166667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>positive</td>\n",
       "      <td>RT @popo_Badman: I was reading an article and ...</td>\n",
       "      <td>deyennie</td>\n",
       "      <td>24</td>\n",
       "      <td>119</td>\n",
       "      <td>4.958333</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>#FEATURED #COURSES\\n\\n#Machine #Learning A-Zâ...</td>\n",
       "      <td>byLilyV</td>\n",
       "      <td>16</td>\n",
       "      <td>137</td>\n",
       "      <td>8.562500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text       user  \\\n",
       "45   neutral  RT @Eli_Krumova: How to Evaluate a #DataScienc...  seerberos   \n",
       "38  positive  RT @popo_Badman: I was reading an article and ...   deyennie   \n",
       "3    neutral  #FEATURED #COURSES\\n\\n#Machine #Learning A-Zâ...    byLilyV   \n",
       "\n",
       "    word_count  char_count  Avg_word_len  len_stop_words  \n",
       "45          12         134     11.166667               2  \n",
       "38          24         119      4.958333              10  \n",
       "3           16         137      8.562500               1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Hashtags and Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_hashtags'] = df['text'].apply(lambda x: len([t for t in x.split() if t.startswith('#')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     7\n",
       "1     7\n",
       "2     7\n",
       "3     7\n",
       "4     0\n",
       "     ..\n",
       "92    1\n",
       "93    3\n",
       "94    0\n",
       "95    0\n",
       "96    3\n",
       "Name: count_hashtags, Length: 97, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['count_hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Avg_word_len</th>\n",
       "      <th>len_stop_words</th>\n",
       "      <th>count_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Jer1dah: Don't sleep on Udemy. There are f...</td>\n",
       "      <td>Siba_Mtshi</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>RT @SuriyaSubraman: Top 5 Data Science Certifi...</td>\n",
       "      <td>epuujee</td>\n",
       "      <td>24</td>\n",
       "      <td>119</td>\n",
       "      <td>4.958333</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neutral</td>\n",
       "      <td>National Big Data Health Science Conference | ...</td>\n",
       "      <td>SuriyaSubraman</td>\n",
       "      <td>19</td>\n",
       "      <td>124</td>\n",
       "      <td>6.526316</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Analyst, Data Science &amp;amp;Â Capabilities http...</td>\n",
       "      <td>hire_pay</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Eli_Krumova: How to Evaluate a #DataScienc...</td>\n",
       "      <td>WomenCodersBot</td>\n",
       "      <td>12</td>\n",
       "      <td>134</td>\n",
       "      <td>11.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "7    neutral  RT @Jer1dah: Don't sleep on Udemy. There are f...   \n",
       "4   positive  RT @SuriyaSubraman: Top 5 Data Science Certifi...   \n",
       "9    neutral  National Big Data Health Science Conference | ...   \n",
       "10   neutral  Analyst, Data Science &amp;Â Capabilities http...   \n",
       "48   neutral  RT @Eli_Krumova: How to Evaluate a #DataScienc...   \n",
       "\n",
       "              user  word_count  char_count  Avg_word_len  len_stop_words  \\\n",
       "7       Siba_Mtshi          24         120      5.000000               8   \n",
       "4          epuujee          24         119      4.958333               9   \n",
       "9   SuriyaSubraman          19         124      6.526316               0   \n",
       "10        hire_pay           6          60     10.000000               0   \n",
       "48  WomenCodersBot          12         134     11.166667               2   \n",
       "\n",
       "    count_hashtags  \n",
       "7                0  \n",
       "4                0  \n",
       "9                0  \n",
       "10               0  \n",
       "48               5  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly for mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Mention'] = df['text'].apply(lambda x: len([t for t in x.split() if t.startswith('@')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Avg_word_len</th>\n",
       "      <th>len_stop_words</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>Mention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@radley_ms @stellaomalley3 There's well establ...</td>\n",
       "      <td>ghhart</td>\n",
       "      <td>15</td>\n",
       "      <td>132</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>positive</td>\n",
       "      <td>RT @Enkkkkkkk7: timely takeaway from today's m...</td>\n",
       "      <td>epuujee</td>\n",
       "      <td>20</td>\n",
       "      <td>123</td>\n",
       "      <td>6.150000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>negative</td>\n",
       "      <td>Climate change: 2020 in a dead heat for world'...</td>\n",
       "      <td>emdeedeedd</td>\n",
       "      <td>22</td>\n",
       "      <td>123</td>\n",
       "      <td>5.590909</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @byLilyV: #FEATURED #COURSES\\n\\n#Machine #L...</td>\n",
       "      <td>epuujee</td>\n",
       "      <td>18</td>\n",
       "      <td>135</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>positive</td>\n",
       "      <td>RT @Ronald_vanLoon: The Union Between #DataSci...</td>\n",
       "      <td>tubbyjpin</td>\n",
       "      <td>13</td>\n",
       "      <td>135</td>\n",
       "      <td>10.384615</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text        user  \\\n",
       "77   neutral  @radley_ms @stellaomalley3 There's well establ...      ghhart   \n",
       "53  positive  RT @Enkkkkkkk7: timely takeaway from today's m...     epuujee   \n",
       "60  negative  Climate change: 2020 in a dead heat for world'...  emdeedeedd   \n",
       "2    neutral  RT @byLilyV: #FEATURED #COURSES\\n\\n#Machine #L...     epuujee   \n",
       "24  positive  RT @Ronald_vanLoon: The Union Between #DataSci...   tubbyjpin   \n",
       "\n",
       "    word_count  char_count  Avg_word_len  len_stop_words  count_hashtags  \\\n",
       "77          15         132      8.800000               3               0   \n",
       "53          20         123      6.150000               7               0   \n",
       "60          22         123      5.590909               7               0   \n",
       "2           18         135      7.500000               1               7   \n",
       "24          13         135     10.384615               1               1   \n",
       "\n",
       "    Mention  \n",
       "77        2  \n",
       "53        1  \n",
       "60        0  \n",
       "2         1  \n",
       "24        2  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     0\n",
       "4     1\n",
       "     ..\n",
       "92    2\n",
       "93    1\n",
       "94    2\n",
       "95    1\n",
       "96    1\n",
       "Name: Mention, Length: 97, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Mention']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric counts in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     1\n",
       "     ..\n",
       "92    0\n",
       "93    0\n",
       "94    0\n",
       "95    0\n",
       "96    0\n",
       "Name: numerals, Length: 97, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If there are any numerals in the text\n",
    "df['numerals'] = df['text'].apply(lambda x: len([t for t in x.split() if t.isdigit()]))\n",
    "df['numerals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Avg_word_len</th>\n",
       "      <th>len_stop_words</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>Mention</th>\n",
       "      <th>numerals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Jer1dah: Don't sleep on Udemy. There are f...</td>\n",
       "      <td>residentgirlie</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>positive</td>\n",
       "      <td>RT @HarbRimah: Top 5 Data Science Certificatio...</td>\n",
       "      <td>NerdGirlXena</td>\n",
       "      <td>15</td>\n",
       "      <td>130</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>positive</td>\n",
       "      <td>RT @DataScientistsF: Coursera âIBM Data Scie...</td>\n",
       "      <td>chidambara09</td>\n",
       "      <td>15</td>\n",
       "      <td>132</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @EPJscience: âEPJ Data Science appoints D...</td>\n",
       "      <td>ciro</td>\n",
       "      <td>15</td>\n",
       "      <td>132</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @byLilyV: #FEATURED #COURSES\\n\\n#Machine #L...</td>\n",
       "      <td>Women_who_code</td>\n",
       "      <td>18</td>\n",
       "      <td>135</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "78   neutral  RT @Jer1dah: Don't sleep on Udemy. There are f...   \n",
       "56  positive  RT @HarbRimah: Top 5 Data Science Certificatio...   \n",
       "92  positive  RT @DataScientistsF: Coursera âIBM Data Scie...   \n",
       "83   neutral  RT @EPJscience: âEPJ Data Science appoints D...   \n",
       "0    neutral  RT @byLilyV: #FEATURED #COURSES\\n\\n#Machine #L...   \n",
       "\n",
       "              user  word_count  char_count  Avg_word_len  len_stop_words  \\\n",
       "78  residentgirlie          24         120      5.000000               8   \n",
       "56    NerdGirlXena          15         130      8.666667               0   \n",
       "92    chidambara09          15         132      8.800000               0   \n",
       "83            ciro          15         132      8.800000               1   \n",
       "0   Women_who_code          18         135      7.500000               1   \n",
       "\n",
       "    count_hashtags  Mention  numerals  \n",
       "78               0        1         0  \n",
       "56               6        1         1  \n",
       "92               1        2         0  \n",
       "83               0        4         0  \n",
       "0                7        1         0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upper Case Words Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3\n",
       "1     3\n",
       "2     3\n",
       "3     2\n",
       "4     2\n",
       "     ..\n",
       "92    1\n",
       "93    2\n",
       "94    1\n",
       "95    1\n",
       "96    2\n",
       "Name: upper_words, Length: 97, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['upper_words'] = df['text'].apply(lambda x: len([t for t in x.split() if t.isupper()]))\n",
    "df['upper_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Avg_word_len</th>\n",
       "      <th>len_stop_words</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>Mention</th>\n",
       "      <th>numerals</th>\n",
       "      <th>upper_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>positive</td>\n",
       "      <td>RT @pj_ballantyne: In true Gen Z spirit, I did...</td>\n",
       "      <td>Fcorowe</td>\n",
       "      <td>25</td>\n",
       "      <td>120</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @LaForge_AI: How data science is driving in...</td>\n",
       "      <td>hubofml</td>\n",
       "      <td>14</td>\n",
       "      <td>132</td>\n",
       "      <td>9.428571</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>positive</td>\n",
       "      <td>Top 5 Data Science Certifications: Data scienc...</td>\n",
       "      <td>SuriyaSubraman</td>\n",
       "      <td>22</td>\n",
       "      <td>121</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Rwaq: \\Ø§Ø³ØªØ·ÙØ¹ Ø§ÙÙÙÙ ÙØ¨ÙÙ Ø«...</td>\n",
       "      <td>HM2015s</td>\n",
       "      <td>29</td>\n",
       "      <td>220</td>\n",
       "      <td>7.586207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @dhovekamp42: BioNTech Publishes Data on No...</td>\n",
       "      <td>BogdanMaverick</td>\n",
       "      <td>18</td>\n",
       "      <td>125</td>\n",
       "      <td>6.944444</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "69  positive  RT @pj_ballantyne: In true Gen Z spirit, I did...   \n",
       "93   neutral  RT @LaForge_AI: How data science is driving in...   \n",
       "8   positive  Top 5 Data Science Certifications: Data scienc...   \n",
       "32   neutral  RT @Rwaq: \\Ø§Ø³ØªØ·ÙØ¹ Ø§ÙÙÙÙ ÙØ¨ÙÙ Ø«...   \n",
       "40   neutral  RT @dhovekamp42: BioNTech Publishes Data on No...   \n",
       "\n",
       "              user  word_count  char_count  Avg_word_len  len_stop_words  \\\n",
       "69         Fcorowe          25         120      4.800000               9   \n",
       "93         hubofml          14         132      9.428571               2   \n",
       "8   SuriyaSubraman          22         121      5.500000               8   \n",
       "32         HM2015s          29         220      7.586207               0   \n",
       "40  BogdanMaverick          18         125      6.944444               3   \n",
       "\n",
       "    count_hashtags  Mention  numerals  upper_words  \n",
       "69               0        3         0            3  \n",
       "93               3        1         0            2  \n",
       "8                0        0         1            1  \n",
       "32               0        1         0           22  \n",
       "40               2        1         0            1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @dhovekamp42: BioNTech Publishes Data on Novel #mRNA Vaccine Approach to Treat #Autoimmune Diseases in Science https://t.co/kUK1HpWgwQ $â\\x80¦'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[40]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment                                                   neutral\n",
       "text              RT @dhovekamp42: BioNTech Publishes Data on No...\n",
       "user                                                 BogdanMaverick\n",
       "word_count                                                       18\n",
       "char_count                                                      125\n",
       "Avg_word_len                                                6.94444\n",
       "len_stop_words                                                    3\n",
       "count_hashtags                                                    2\n",
       "Mention                                                           1\n",
       "numerals                                                          0\n",
       "upper_words                                                       1\n",
       "lower_words                                                      18\n",
       "Name: 40, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[40]  # iloc: imaginary index number, useful to abtain row and column of a particular cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Case Words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     18\n",
       "1     18\n",
       "2     18\n",
       "3     16\n",
       "4     24\n",
       "      ..\n",
       "92    15\n",
       "93    14\n",
       "94    22\n",
       "95    24\n",
       "96    14\n",
       "Name: lower_words, Length: 97, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lower_words'] = df['text'].apply(lambda x: len([t for t in x.split() if t.lower()]))\n",
    "df['lower_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Avg_word_len</th>\n",
       "      <th>len_stop_words</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>Mention</th>\n",
       "      <th>numerals</th>\n",
       "      <th>upper_words</th>\n",
       "      <th>lower_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Jer1dah: Don't sleep on Udemy. There are f...</td>\n",
       "      <td>LungileGodwana</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>negative</td>\n",
       "      <td>RT @PandhareSidhesh: Exploit the Economics of ...</td>\n",
       "      <td>epuujee</td>\n",
       "      <td>16</td>\n",
       "      <td>127</td>\n",
       "      <td>7.9375</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Jer1dah: Don't sleep on Udemy. There are f...</td>\n",
       "      <td>GiftOfShange</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "15   neutral  RT @Jer1dah: Don't sleep on Udemy. There are f...   \n",
       "28  negative  RT @PandhareSidhesh: Exploit the Economics of ...   \n",
       "72   neutral  RT @Jer1dah: Don't sleep on Udemy. There are f...   \n",
       "\n",
       "              user  word_count  char_count  Avg_word_len  len_stop_words  \\\n",
       "15  LungileGodwana          24         120        5.0000               8   \n",
       "28         epuujee          16         127        7.9375               4   \n",
       "72    GiftOfShange          24         120        5.0000               8   \n",
       "\n",
       "    count_hashtags  Mention  numerals  upper_words  lower_words  \n",
       "15               0        1         0            1           24  \n",
       "28               2        1         0            1           16  \n",
       "72               0        1         0            1           24  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     rt @bylilyv: #featured #courses\\n\\n#machine #l...\n",
       "1     rt @bylilyv: #featured #courses\\n\\n#machine #l...\n",
       "2     rt @bylilyv: #featured #courses\\n\\n#machine #l...\n",
       "3     #featured #courses\\n\\n#machine #learning a-zâ...\n",
       "4     rt @suriyasubraman: top 5 data science certifi...\n",
       "                            ...                        \n",
       "92    rt @datascientistsf: coursera âibm data scie...\n",
       "93    rt @laforge_ai: how data science is driving in...\n",
       "94    rt @theriversevern: anyone want to join @wufou...\n",
       "95    rt @jer1dah: don't sleep on udemy. there are f...\n",
       "96    rt @laforge_ai: how data science is driving in...\n",
       "Name: text, Length: 97, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(lambda x:str(x).lower()) # lower case text : the whole text\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Avg_word_len</th>\n",
       "      <th>len_stop_words</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>Mention</th>\n",
       "      <th>numerals</th>\n",
       "      <th>upper_words</th>\n",
       "      <th>lower_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>negative</td>\n",
       "      <td>rt @nelth_fr: @ravinwashere okay now explain t...</td>\n",
       "      <td>Artificialbra1n</td>\n",
       "      <td>18</td>\n",
       "      <td>127</td>\n",
       "      <td>7.055556</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>neutral</td>\n",
       "      <td>how to evaluate a #datascience project\\nhttps:...</td>\n",
       "      <td>Eli_Krumova</td>\n",
       "      <td>10</td>\n",
       "      <td>133</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @laforge_ai: how data science is driving in...</td>\n",
       "      <td>hubofml</td>\n",
       "      <td>14</td>\n",
       "      <td>132</td>\n",
       "      <td>9.428571</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @jer1dah: don't sleep on udemy. there are f...</td>\n",
       "      <td>_Ignatia_</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "11  negative  rt @nelth_fr: @ravinwashere okay now explain t...   \n",
       "51   neutral  how to evaluate a #datascience project\\nhttps:...   \n",
       "93   neutral  rt @laforge_ai: how data science is driving in...   \n",
       "70   neutral  rt @jer1dah: don't sleep on udemy. there are f...   \n",
       "\n",
       "               user  word_count  char_count  Avg_word_len  len_stop_words  \\\n",
       "11  Artificialbra1n          18         127      7.055556               5   \n",
       "51      Eli_Krumova          10         133     13.300000               2   \n",
       "93          hubofml          14         132      9.428571               2   \n",
       "70        _Ignatia_          24         120      5.000000               8   \n",
       "\n",
       "    count_hashtags  Mention  numerals  upper_words  lower_words  \n",
       "11               0        2         0            1           18  \n",
       "51               4        0         0            2           10  \n",
       "93               3        1         0            2           14  \n",
       "70               0        1         0            1           24  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contraction To Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eg: could'nt == could not, don't = do not, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions{\n",
    "\"isn't\" : \"is not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"don't\" : \"do not\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is / how does\",\n",
    "\"I'd\": \"I had / I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I shall / I will\",\n",
    "\"I'll've\": \"I shall have / I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_to_exp(x):\n",
    "    if type(x) is str:\n",
    "        for key in contractions:\n",
    "            value = contractions[key]\n",
    "            x = x.replace(key, value)\n",
    "        return x\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is not my work'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"this isn't my work\"\n",
    "con_to_exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.1 ms ± 6.09 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df['text'] = df['text'].apply(lambda x: con_to_exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Avg_word_len</th>\n",
       "      <th>len_stop_words</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>Mention</th>\n",
       "      <th>numerals</th>\n",
       "      <th>upper_words</th>\n",
       "      <th>lower_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @jer1dah: do not sleep on udemy. there are ...</td>\n",
       "      <td>GiftOfShange</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @dhovekamp42: biontech publishes data on no...</td>\n",
       "      <td>epuujee</td>\n",
       "      <td>18</td>\n",
       "      <td>125</td>\n",
       "      <td>6.944444</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>neutral</td>\n",
       "      <td>how data science is driving genomics in the #p...</td>\n",
       "      <td>Hydrogen_LS</td>\n",
       "      <td>12</td>\n",
       "      <td>83</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @wsjp_insight: https://t.co/rsure6q7qn\\n39 ...</td>\n",
       "      <td>WSlightly</td>\n",
       "      <td>9</td>\n",
       "      <td>135</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text          user  \\\n",
       "72   neutral  rt @jer1dah: do not sleep on udemy. there are ...  GiftOfShange   \n",
       "39   neutral  rt @dhovekamp42: biontech publishes data on no...       epuujee   \n",
       "30   neutral  how data science is driving genomics in the #p...   Hydrogen_LS   \n",
       "37   neutral  rt @wsjp_insight: https://t.co/rsure6q7qn\\n39 ...     WSlightly   \n",
       "\n",
       "    word_count  char_count  Avg_word_len  len_stop_words  count_hashtags  \\\n",
       "72          24         120      5.000000               8               0   \n",
       "39          18         125      6.944444               3               2   \n",
       "30          12          83      6.916667               3               1   \n",
       "37           9         135     15.000000               0               0   \n",
       "\n",
       "    Mention  numerals  upper_words  lower_words  \n",
       "72        1         0            1           24  \n",
       "39        1         0            1           18  \n",
       "30        0         0            0           12  \n",
       "37        1         0            1            9  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## counting and Removing E-mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Avg_word_len</th>\n",
       "      <th>len_stop_words</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>Mention</th>\n",
       "      <th>numerals</th>\n",
       "      <th>upper_words</th>\n",
       "      <th>lower_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentiment, text, user, word_count, char_count, Avg_word_len, len_stop_words, count_hashtags, Mention, numerals, upper_words, lower_words]\n",
       "Index: []"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].str.contains('gmail.com')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how data science is driving genomics in the #pharmaceutical industry - https://t.co/1vwuhqmbia'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[30]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = re.findall(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+\\b)', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     []\n",
       "1     []\n",
       "2     []\n",
       "3     []\n",
       "4     []\n",
       "      ..\n",
       "92    []\n",
       "93    []\n",
       "94    []\n",
       "95    []\n",
       "96    []\n",
       "Name: text, Length: 97, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].apply(lambda x: emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emails_count'] = df['text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     152\n",
       "1     152\n",
       "2     152\n",
       "3     152\n",
       "4     142\n",
       "     ... \n",
       "92    146\n",
       "93    145\n",
       "94    142\n",
       "95    144\n",
       "96    145\n",
       "Name: emails_count, Length: 97, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emails_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Avg_word_len</th>\n",
       "      <th>len_stop_words</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>Mention</th>\n",
       "      <th>numerals</th>\n",
       "      <th>upper_words</th>\n",
       "      <th>lower_words</th>\n",
       "      <th>emails_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @bylilyv: #featured #courses\\n\\n#machine #l...</td>\n",
       "      <td>Women_who_code</td>\n",
       "      <td>18</td>\n",
       "      <td>135</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>negative</td>\n",
       "      <td>rt @writingreliable: hire us to do your;\\nstat...</td>\n",
       "      <td>epuujee</td>\n",
       "      <td>10</td>\n",
       "      <td>142</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>positive</td>\n",
       "      <td>rt @bukmedianet: data science 2020 : complete ...</td>\n",
       "      <td>datasciencebot_</td>\n",
       "      <td>16</td>\n",
       "      <td>136</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @eli_krumova: how to evaluate a #datascienc...</td>\n",
       "      <td>LeetcodeB</td>\n",
       "      <td>12</td>\n",
       "      <td>134</td>\n",
       "      <td>11.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0    neutral  rt @bylilyv: #featured #courses\\n\\n#machine #l...   \n",
       "66  negative  rt @writingreliable: hire us to do your;\\nstat...   \n",
       "89  positive  rt @bukmedianet: data science 2020 : complete ...   \n",
       "23   neutral  rt @eli_krumova: how to evaluate a #datascienc...   \n",
       "\n",
       "               user  word_count  char_count  Avg_word_len  len_stop_words  \\\n",
       "0    Women_who_code          18         135      7.500000               1   \n",
       "66          epuujee          10         142     14.200000               3   \n",
       "89  datasciencebot_          16         136      8.500000               0   \n",
       "23        LeetcodeB          12         134     11.166667               2   \n",
       "\n",
       "    count_hashtags  Mention  numerals  upper_words  lower_words  emails_count  \n",
       "0                7        1         0            3           18           152  \n",
       "66               0        1         0            1           10           151  \n",
       "89               2        1         1            1           16           151  \n",
       "23               5        1         0            3           12           145  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Avg_word_len</th>\n",
       "      <th>len_stop_words</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>Mention</th>\n",
       "      <th>numerals</th>\n",
       "      <th>upper_words</th>\n",
       "      <th>lower_words</th>\n",
       "      <th>emails_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @bylilyv: #featured #courses\\n\\n#machine #l...</td>\n",
       "      <td>Women_who_code</td>\n",
       "      <td>18</td>\n",
       "      <td>135</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @bylilyv: #featured #courses\\n\\n#machine #l...</td>\n",
       "      <td>xaelbot</td>\n",
       "      <td>18</td>\n",
       "      <td>135</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @bylilyv: #featured #courses\\n\\n#machine #l...</td>\n",
       "      <td>epuujee</td>\n",
       "      <td>18</td>\n",
       "      <td>135</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>#featured #courses\\n\\n#machine #learning a-zâ...</td>\n",
       "      <td>byLilyV</td>\n",
       "      <td>16</td>\n",
       "      <td>137</td>\n",
       "      <td>8.562500</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>rt @suriyasubraman: top 5 data science certifi...</td>\n",
       "      <td>epuujee</td>\n",
       "      <td>24</td>\n",
       "      <td>119</td>\n",
       "      <td>4.958333</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>positive</td>\n",
       "      <td>rt @datascientistsf: coursera âibm data scie...</td>\n",
       "      <td>chidambara09</td>\n",
       "      <td>15</td>\n",
       "      <td>132</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @laforge_ai: how data science is driving in...</td>\n",
       "      <td>hubofml</td>\n",
       "      <td>14</td>\n",
       "      <td>132</td>\n",
       "      <td>9.428571</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @theriversevern: anyone want to join @wufou...</td>\n",
       "      <td>epuujee</td>\n",
       "      <td>22</td>\n",
       "      <td>121</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @jer1dah: do not sleep on udemy. there are ...</td>\n",
       "      <td>DiatonicM</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @laforge_ai: how data science is driving in...</td>\n",
       "      <td>andrewmorrisuk</td>\n",
       "      <td>14</td>\n",
       "      <td>132</td>\n",
       "      <td>9.428571</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0    neutral  rt @bylilyv: #featured #courses\\n\\n#machine #l...   \n",
       "1    neutral  rt @bylilyv: #featured #courses\\n\\n#machine #l...   \n",
       "2    neutral  rt @bylilyv: #featured #courses\\n\\n#machine #l...   \n",
       "3    neutral  #featured #courses\\n\\n#machine #learning a-zâ...   \n",
       "4   positive  rt @suriyasubraman: top 5 data science certifi...   \n",
       "..       ...                                                ...   \n",
       "92  positive  rt @datascientistsf: coursera âibm data scie...   \n",
       "93   neutral  rt @laforge_ai: how data science is driving in...   \n",
       "94   neutral  rt @theriversevern: anyone want to join @wufou...   \n",
       "95   neutral  rt @jer1dah: do not sleep on udemy. there are ...   \n",
       "96   neutral  rt @laforge_ai: how data science is driving in...   \n",
       "\n",
       "              user  word_count  char_count  Avg_word_len  len_stop_words  \\\n",
       "0   Women_who_code          18         135      7.500000               1   \n",
       "1          xaelbot          18         135      7.500000               1   \n",
       "2          epuujee          18         135      7.500000               1   \n",
       "3          byLilyV          16         137      8.562500               1   \n",
       "4          epuujee          24         119      4.958333               9   \n",
       "..             ...         ...         ...           ...             ...   \n",
       "92    chidambara09          15         132      8.800000               0   \n",
       "93         hubofml          14         132      9.428571               2   \n",
       "94         epuujee          22         121      5.500000               8   \n",
       "95       DiatonicM          24         120      5.000000               8   \n",
       "96  andrewmorrisuk          14         132      9.428571               2   \n",
       "\n",
       "    count_hashtags  Mention  numerals  upper_words  lower_words  emails_count  \n",
       "0                7        1         0            3           18           152  \n",
       "1                7        1         0            3           18           152  \n",
       "2                7        1         0            3           18           152  \n",
       "3                7        0         0            2           16           152  \n",
       "4                0        1         1            2           24           142  \n",
       "..             ...      ...       ...          ...          ...           ...  \n",
       "92               1        2         0            1           15           146  \n",
       "93               3        1         0            2           14           145  \n",
       "94               0        2         0            1           22           142  \n",
       "95               0        1         0            1           24           144  \n",
       "96               3        1         0            2           14           145  \n",
       "\n",
       "[97 rows x 13 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['emails_count']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)', \" \",x) # will return an empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)', \" \",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Avg_word_len</th>\n",
       "      <th>len_stop_words</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>Mention</th>\n",
       "      <th>numerals</th>\n",
       "      <th>upper_words</th>\n",
       "      <th>lower_words</th>\n",
       "      <th>emails_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @bylilyv: #featured #courses\\n\\n#machine #l...</td>\n",
       "      <td>Women_who_code</td>\n",
       "      <td>18</td>\n",
       "      <td>135</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @bylilyv: #featured #courses\\n\\n#machine #l...</td>\n",
       "      <td>xaelbot</td>\n",
       "      <td>18</td>\n",
       "      <td>135</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @bylilyv: #featured #courses\\n\\n#machine #l...</td>\n",
       "      <td>epuujee</td>\n",
       "      <td>18</td>\n",
       "      <td>135</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>#featured #courses\\n\\n#machine #learning a-zâ...</td>\n",
       "      <td>byLilyV</td>\n",
       "      <td>16</td>\n",
       "      <td>137</td>\n",
       "      <td>8.562500</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>rt @suriyasubraman: top 5 data science certifi...</td>\n",
       "      <td>epuujee</td>\n",
       "      <td>24</td>\n",
       "      <td>119</td>\n",
       "      <td>4.958333</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>positive</td>\n",
       "      <td>rt @datascientistsf: coursera âibm data scie...</td>\n",
       "      <td>chidambara09</td>\n",
       "      <td>15</td>\n",
       "      <td>132</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @laforge_ai: how data science is driving in...</td>\n",
       "      <td>hubofml</td>\n",
       "      <td>14</td>\n",
       "      <td>132</td>\n",
       "      <td>9.428571</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @theriversevern: anyone want to join @wufou...</td>\n",
       "      <td>epuujee</td>\n",
       "      <td>22</td>\n",
       "      <td>121</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @jer1dah: do not sleep on udemy. there are ...</td>\n",
       "      <td>DiatonicM</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt @laforge_ai: how data science is driving in...</td>\n",
       "      <td>andrewmorrisuk</td>\n",
       "      <td>14</td>\n",
       "      <td>132</td>\n",
       "      <td>9.428571</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0    neutral  rt @bylilyv: #featured #courses\\n\\n#machine #l...   \n",
       "1    neutral  rt @bylilyv: #featured #courses\\n\\n#machine #l...   \n",
       "2    neutral  rt @bylilyv: #featured #courses\\n\\n#machine #l...   \n",
       "3    neutral  #featured #courses\\n\\n#machine #learning a-zâ...   \n",
       "4   positive  rt @suriyasubraman: top 5 data science certifi...   \n",
       "..       ...                                                ...   \n",
       "92  positive  rt @datascientistsf: coursera âibm data scie...   \n",
       "93   neutral  rt @laforge_ai: how data science is driving in...   \n",
       "94   neutral  rt @theriversevern: anyone want to join @wufou...   \n",
       "95   neutral  rt @jer1dah: do not sleep on udemy. there are ...   \n",
       "96   neutral  rt @laforge_ai: how data science is driving in...   \n",
       "\n",
       "              user  word_count  char_count  Avg_word_len  len_stop_words  \\\n",
       "0   Women_who_code          18         135      7.500000               1   \n",
       "1          xaelbot          18         135      7.500000               1   \n",
       "2          epuujee          18         135      7.500000               1   \n",
       "3          byLilyV          16         137      8.562500               1   \n",
       "4          epuujee          24         119      4.958333               9   \n",
       "..             ...         ...         ...           ...             ...   \n",
       "92    chidambara09          15         132      8.800000               0   \n",
       "93         hubofml          14         132      9.428571               2   \n",
       "94         epuujee          22         121      5.500000               8   \n",
       "95       DiatonicM          24         120      5.000000               8   \n",
       "96  andrewmorrisuk          14         132      9.428571               2   \n",
       "\n",
       "    count_hashtags  Mention  numerals  upper_words  lower_words  emails_count  \n",
       "0                7        1         0            3           18           152  \n",
       "1                7        1         0            3           18           152  \n",
       "2                7        1         0            3           18           152  \n",
       "3                7        0         0            2           16           152  \n",
       "4                0        1         1            2           24           142  \n",
       "..             ...      ...       ...          ...          ...           ...  \n",
       "92               1        2         0            1           15           146  \n",
       "93               3        1         0            2           14           145  \n",
       "94               0        2         0            1           22           142  \n",
       "95               0        1         0            1           24           144  \n",
       "96               3        1         0            2           14           145  \n",
       "\n",
       "[97 rows x 13 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['emails_count']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this isn't my work\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].str.contains('rt')] # rt == retweet\n",
    "df['text'].apply(lambda x : re.sub(r'\\brt]b', '', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count urls and remove urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_url = re.findall(r'(https|http|ftp|ssh)://([w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url_flags_count'] = df['text'].apply(lambda x: count_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['url_flags_count']>0].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for removal use re.sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specialchara and puctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_char = re.sub(r'[^\\w ]+', \"\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x : special_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67    this isnt my work\n",
       "88    this isnt my work\n",
       "74    this isnt my work\n",
       "53    this isnt my work\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Multiple spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "df['text'] = df['text'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove accented char\n",
    "\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accen_char(x):\n",
    "    x = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this isn't my work\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_accen_char(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: ' '.join([t for t in x.split() if t not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer as wnl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_word(x):\n",
    "    x = str(x)\n",
    "    x_list = []\n",
    "    doc = nlp(x)\n",
    "    \n",
    "    for token in doc:\n",
    "        lemma = token.lemma_\n",
    "        if lemma == '-PRON-' or lemma == 'be':\n",
    "            lemma = token.text\n",
    "        \n",
    "        x_list.append(lemma)\n",
    "    return ' '.join(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is not my work'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_word(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## common / frequent words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      isnt\n",
       "1      work\n",
       "2      isnt\n",
       "3      work\n",
       "4      isnt\n",
       "       ... \n",
       "189    work\n",
       "190    isnt\n",
       "191    work\n",
       "192    isnt\n",
       "193    work\n",
       "Length: 194, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work    97\n",
       "isnt    97\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_common = pd.Series(text).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f10 = freq_common[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: ' '.join( [for t in x.split() if t not in f10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rare words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare = freq_common.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: ' '.join( [for t in x.split() if t not in rare]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word cloud visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.1-cp37-cp37m-win_amd64.whl (154 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wordcloud) (2.2.5)\n",
      "Requirement already satisfied: pillow in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wordcloud) (7.0.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wordcloud) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\admin\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\admin\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib->wordcloud) (1.15.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2019.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->wordcloud) (50.3.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wc = WordCloud(width=800, height=400).generate(text)\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## # Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ' thnks it is gret'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = TextBlob(x).correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\" thanks it is great\")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization sing textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ' Thenks it is gret, i enjoid it'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Thenks', 'it', 'is', 'gret', 'i', 'enjoid', 'it'])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(x).words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Thenks\n",
      "it\n",
      "is\n",
      "gret\n",
      ",\n",
      "i\n",
      "enjoid\n",
      "it\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(x)\n",
    "for token in doc:\n",
    "    print(token)  # spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization in nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETECTING NOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Thenks\n",
      "it\n",
      "i\n",
      "it\n"
     ]
    }
   ],
   "source": [
    "for noun in doc.noun_chunks:\n",
    "    print(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language translation and detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Thenks it is gret, i enjoid it'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = TextBlob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Entonces es genial, lo disfruté\")"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.translate(to = 'es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit codes for the representation of names of languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentiment classifier in textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'we all stands together'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"we all stands together\")"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(x , analyzer=NaiveBayesAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
